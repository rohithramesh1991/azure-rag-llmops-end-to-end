# ğŸ§  Azure RAG LLMOps End-to-End

An end-to-end **Retrieval-Augmented Generation (RAG)** application built with **FastAPI**, **LangChain**, and **Azure OpenAI**.  
This project demonstrates how to integrate embeddings, semantic search, and LLM responses into a production-ready app that can later be deployed on Azure.

---

## ğŸš€ Overview

This project implements a RAG workflow where:
1. Documents are **embedded** using Azure OpenAIâ€™s Embedding API.  
2. Embeddings are **stored and queried** in **Azure Cognitive Search**.  
3. A **FastAPI backend** serves user queries and combines search results with **LLM completions**.  
4. Metrics and health checks are exposed for observability and monitoring.

---

## ğŸ§© Architecture

User Query â†’ FastAPI â†’ Azure OpenAI (Embedding + Chat)
â†˜ Azure Cognitive Search (Retrieval)


Key Components:
- **FastAPI** â€” serves `/ask`, `/healthz`, and `/readyz` endpoints.  
- **Azure OpenAI** â€” provides embeddings and LLM completions.  
- **LangChain** â€” integrates embeddings and vector search.  
- **Azure Cognitive Search** â€” performs similarity search on stored embeddings.  
- **Prometheus metrics** â€” optional, for monitoring response times and health.

---

## ğŸ“ Project Structure

```azure-rag-llmops-end-to-end/
â”‚
â”œâ”€â”€ webapp/ # Main FastAPI application
â”‚ â”œâ”€â”€ main.py # Core app logic and routes
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ ingest/ # (Optional) Data ingestion scripts for embeddings
â”‚
â”œâ”€â”€ data/ # Example CSVs or text data
â”‚
â”œâ”€â”€ test/ # Unit and integration tests (pytest)
â”‚ â”œâ”€â”€ test_core.py
â”‚ â”œâ”€â”€ test_health.py
â”‚ â””â”€â”€ test_integration.py
â”‚
â”œâ”€â”€ .github/workflows/ # GitHub Actions CI/CD (to be added later)
â”‚
â”œâ”€â”€ Dockerfile # Container image definition
â”œâ”€â”€ pyproject.toml # Dependencies and build configuration
â”œâ”€â”€ quickcheck.py # Quick local testing script
â””â”€â”€ README.md
```

